{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adarsh0911/Elements-of-Aiml-LAb-Adarsh-Singh/blob/main/Aiml_exp_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate an imbalanced dataset\n",
        "X, y = make_classification(\n",
        "    n_classes=2,\n",
        "    class_sep=2,\n",
        "    weights=[0.9, 0.1], # 90% majority, 10% minority\n",
        "    n_informative=3,\n",
        "    n_redundant=1,\n",
        "    flip_y=0,\n",
        "    n_features=5,\n",
        "    n_clusters_per_class=1,\n",
        "    n_samples=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(X, columns=[f\"Feature_{i}\" for i in range(X.shape[1])])\n",
        "df['Target'] = y\n",
        "\n",
        "# Display basic details\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Show class distribution\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(df['Target'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toUKAyeZMBcX",
        "outputId": "6d85e522-3e3f-41ac-ae29-52f6cf5425a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Feature_0  1000 non-null   float64\n",
            " 1   Feature_1  1000 non-null   float64\n",
            " 2   Feature_2  1000 non-null   float64\n",
            " 3   Feature_3  1000 non-null   float64\n",
            " 4   Feature_4  1000 non-null   float64\n",
            " 5   Target     1000 non-null   int64  \n",
            "dtypes: float64(5), int64(1)\n",
            "memory usage: 47.0 KB\n",
            "None\n",
            "\n",
            "Class Distribution:\n",
            "Target\n",
            "0    900\n",
            "1    100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled_ros, y_resampled_ros = ros.fit_resample(X, y)\n",
        "\n",
        "print(\"\\nClass Distribution After Random Oversampling:\")\n",
        "print(pd.Series(y_resampled_ros).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNbfZ1ufMJiV",
        "outputId": "60b70a68-2f31-4f84-8889-b2063cb44b9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution After Random Oversampling:\n",
            "0    900\n",
            "1    900\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled_rus, y_resampled_rus = rus.fit_resample(X, y)\n",
        "\n",
        "print(\"\\nClass Distribution After Random Undersampling:\")\n",
        "print(pd.Series(y_resampled_rus).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6d_lmXQMPLZ",
        "outputId": "337d7e0e-dcdc-4887-a13c-5f6a88ada70f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution After Random Undersampling:\n",
            "0    100\n",
            "1    100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_smote, y_resampled_smote = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"\\nClass Distribution After SMOTE:\")\n",
        "print(pd.Series(y_resampled_smote).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBw-GiKKMWMD",
        "outputId": "85fcb3e7-bf03-4119-8bb0-3c0f3ef08e3a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution After SMOTE:\n",
            "0    900\n",
            "1    900\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Function to train and evaluate a classifier\n",
        "def evaluate_classifier(X_train, X_test, y_train, y_test, class_weight=None):\n",
        "    model = LogisticRegression(class_weight=class_weight, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Performance Metrics\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "\n",
        "# Split the original dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(\"\\nPerformance on Imbalanced Dataset:\")\n",
        "evaluate_classifier(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Oversampled\n",
        "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
        "print(\"\\nPerformance After Random Oversampling:\")\n",
        "evaluate_classifier(X_train_ros, X_test, y_train_ros, y_test)\n",
        "\n",
        "# Undersampled\n",
        "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
        "print(\"\\nPerformance After Random Undersampling:\")\n",
        "evaluate_classifier(X_train_rus, X_test, y_train_rus, y_test)\n",
        "\n",
        "# SMOTE\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "print(\"\\nPerformance After SMOTE:\")\n",
        "evaluate_classifier(X_train_smote, X_test, y_train_smote, y_test)\n",
        "\n",
        "# Class Weighting\n",
        "print(\"\\nPerformance with Class Weighting:\")\n",
        "evaluate_classifier(X_train, X_test, y_train, y_test, class_weight='balanced')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hjDcd3RMk8b",
        "outputId": "ef06f915-dbc0-4dea-ba4f-2a4aeca50b6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performance on Imbalanced Dataset:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       270\n",
            "           1       1.00      1.00      1.00        30\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       1.00      1.00      1.00       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Performance After Random Oversampling:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       270\n",
            "           1       0.97      1.00      0.98        30\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       0.98      1.00      0.99       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Performance After Random Undersampling:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       270\n",
            "           1       0.97      1.00      0.98        30\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       0.98      1.00      0.99       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Performance After SMOTE:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       270\n",
            "           1       0.97      1.00      0.98        30\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       0.98      1.00      0.99       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Performance with Class Weighting:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       270\n",
            "           1       0.97      1.00      0.98        30\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       0.98      1.00      0.99       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "AUC-ROC: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Function to collect metrics\n",
        "def get_metrics(y_test, y_pred, y_pred_proba):\n",
        "    return {\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_pred_proba)\n",
        "    }\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {}\n",
        "\n",
        "# Evaluate each method and collect metrics\n",
        "methods = {\n",
        "    \"Imbalanced\": (X_train, y_train, None),\n",
        "    \"Oversampling\": (X_train_ros, y_train_ros, None),\n",
        "    \"Undersampling\": (X_train_rus, y_train_rus, None),\n",
        "    \"SMOTE\": (X_train_smote, y_train_smote, None),\n",
        "    \"Class Weighting\": (X_train, y_train, 'balanced')\n",
        "}\n",
        "\n",
        "for method, (X_train_balanced, y_train_balanced, weight) in methods.items():\n",
        "    model = LogisticRegression(class_weight=weight, random_state=42)\n",
        "    model.fit(X_train_balanced, y_train_balanced)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    metrics[method] = get_metrics(y_test, y_pred, y_pred_proba)\n",
        "\n",
        "# Display metrics\n",
        "metrics_df = pd.DataFrame(metrics).T\n",
        "print(\"\\nPerformance Metrics Summary:\")\n",
        "print(metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmAOxopjMqEi",
        "outputId": "885a74cf-fb82-4478-dc5d-7f543deaacbf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performance Metrics Summary:\n",
            "                 Precision  Recall  F1-Score  AUC-ROC\n",
            "Imbalanced        1.000000     1.0  1.000000      1.0\n",
            "Oversampling      0.967742     1.0  0.983607      1.0\n",
            "Undersampling     0.967742     1.0  0.983607      1.0\n",
            "SMOTE             0.967742     1.0  0.983607      1.0\n",
            "Class Weighting   0.967742     1.0  0.983607      1.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}